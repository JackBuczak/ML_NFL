{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5536b2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "col_names = ['date', 'season', 'neutral', 'playoff', 'team1', 'team2', 'elo1_pre', 'elo2_pre', 'elo_prob1', 'elo_prob2', 'elo1_post',\n",
    "             'elo2_post', 'qbelo1_pre', 'qbelo2_pre', 'qb1', 'qb2', 'qb1_value_pre', 'qb2_value_pre', 'qb1_adj', 'qb2_adj', \n",
    "             'qbelo_prob1', 'qbelo_prob2', 'qb1_game_value', 'qb2_game_value', 'qb1_value_post', 'qb2_value_post', 'qbelo1_post',\n",
    "             'qbelo2_post', 'score1', 'score2', 'quality', 'importance', 'total_rating']\n",
    "\n",
    "# load dataset\n",
    "data = pd.read_csv(\"nfl_elo.csv\", header=None, names=col_names)\n",
    "data = data.drop(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff7ecd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through rows and replace NaN values in 'playoff' with 'r', signifying \"Regular Season\"\n",
    "for index, row in data.iterrows():\n",
    "    if pd.isna(row['playoff']):\n",
    "        data.at[index, 'playoff'] = 'r'        \n",
    "\n",
    "# Dropping last 3 columns        \n",
    "data = data.drop(['quality', 'importance', 'total_rating', 'date'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc869106",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change categorical values to numeric values\n",
    "\n",
    "# Importing LabelEncoder from Sklearn \n",
    "# library from preprocessing Module.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    " \n",
    "# Creating a instance of label Encoder.\n",
    "le = LabelEncoder()\n",
    " \n",
    "# Using .fit_transform function to fit label\n",
    "# encoder and return encoded label\n",
    "l1 = le.fit_transform(data['team1'])\n",
    "\n",
    "data.drop(\"team1\", axis=1, inplace=True)\n",
    " \n",
    "# Appending the array to our dataFrame \n",
    "# with column name 'Purchased'\n",
    "data[\"team1\"] = l1\n",
    "\n",
    "#repeat for the rest of the categorical values\n",
    "l2 = le.fit_transform(data['team2'])\n",
    "data.drop(\"team2\", axis=1, inplace=True)\n",
    "data[\"team2\"] = l2\n",
    "\n",
    "l3 = le.fit_transform(data['qb1'])\n",
    "data.drop(\"qb1\", axis=1, inplace=True)\n",
    "data[\"qb1\"] = l3\n",
    "\n",
    "l4 = le.fit_transform(data['qb2'])\n",
    "data.drop(\"qb2\", axis=1, inplace=True)\n",
    "data[\"qb2\"] = l4\n",
    "\n",
    "#change categorical values to numeric values\n",
    "\n",
    "# Importing LabelEncoder from Sklearn \n",
    "# library from preprocessing Module.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    " \n",
    "# Creating a instance of label Encoder.\n",
    "le = LabelEncoder()\n",
    " \n",
    "# Using .fit_transform function to fit label\n",
    "# encoder and return encoded label\n",
    "l1 = le.fit_transform(data['team1'])\n",
    "\n",
    "data.drop(\"team1\", axis=1, inplace=True)\n",
    " \n",
    "# Appending the array to our dataFrame \n",
    "# with column name 'Purchased'\n",
    "data[\"team1\"] = l1\n",
    "\n",
    "#repeat for the rest of the categorical values\n",
    "l2 = le.fit_transform(data['team2'])\n",
    "data.drop(\"team2\", axis=1, inplace=True)\n",
    "data[\"team2\"] = l2\n",
    "\n",
    "l3 = le.fit_transform(data['qb1'])\n",
    "data.drop(\"qb1\", axis=1, inplace=True)\n",
    "data[\"qb1\"] = l3\n",
    "\n",
    "l4 = le.fit_transform(data['qb2'])\n",
    "data.drop(\"qb2\", axis=1, inplace=True)\n",
    "data[\"qb2\"] = l4\n",
    "\n",
    "l5 = le.fit_transform(data['playoff'])  \n",
    "data.drop(\"playoff\", axis=1, inplace=True)\n",
    "data[\"playoff\"] = l5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "851e1bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add column for win/loss result. 0 means team1 lost, 1 means team1 won. -1 indicates a tie.\n",
    "def compare_scores(score1, score2):\n",
    "    if score1 < score2:\n",
    "        return 0\n",
    "    elif score1 > score2:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1  # Return a special value indicating that the scores are equal\n",
    "\n",
    "data['outcome'] = data.apply(lambda row: compare_scores(float(row['score1']), float(row['score2'])), axis=1)\n",
    "\n",
    "# Remove rows where the scores are equal\n",
    "data = data[data['outcome'] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07fb28a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 15069 entries, 1 to 15217\n",
      "Data columns (total 30 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   season          15069 non-null  object\n",
      " 1   neutral         15069 non-null  object\n",
      " 2   elo1_pre        15069 non-null  object\n",
      " 3   elo2_pre        15069 non-null  object\n",
      " 4   elo_prob1       15069 non-null  object\n",
      " 5   elo_prob2       15069 non-null  object\n",
      " 6   elo1_post       15069 non-null  object\n",
      " 7   elo2_post       15069 non-null  object\n",
      " 8   qbelo1_pre      15069 non-null  object\n",
      " 9   qbelo2_pre      15069 non-null  object\n",
      " 10  qb1_value_pre   15069 non-null  object\n",
      " 11  qb2_value_pre   15069 non-null  object\n",
      " 12  qb1_adj         15069 non-null  object\n",
      " 13  qb2_adj         15069 non-null  object\n",
      " 14  qbelo_prob1     15069 non-null  object\n",
      " 15  qbelo_prob2     15069 non-null  object\n",
      " 16  qb1_game_value  15069 non-null  object\n",
      " 17  qb2_game_value  15069 non-null  object\n",
      " 18  qb1_value_post  15069 non-null  object\n",
      " 19  qb2_value_post  15069 non-null  object\n",
      " 20  qbelo1_post     15069 non-null  object\n",
      " 21  qbelo2_post     15069 non-null  object\n",
      " 22  score1          15069 non-null  object\n",
      " 23  score2          15069 non-null  object\n",
      " 24  team1           15069 non-null  int64 \n",
      " 25  team2           15069 non-null  int64 \n",
      " 26  qb1             15069 non-null  int64 \n",
      " 27  qb2             15069 non-null  int64 \n",
      " 28  playoff         15069 non-null  int64 \n",
      " 29  outcome         15069 non-null  int64 \n",
      "dtypes: int64(6), object(24)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "149e420e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#from sklearn.neighbors import DistanceMetric\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "import matplotlib.pyplot as plt #so you can draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48460f80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ee64f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import module to standardize the scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Create instance (i.e. object) of the standard scaler\n",
    "scaler = StandardScaler()\n",
    "# Fit the object to all the data except the Target/Outcome\n",
    "# use the .drop() method to gather all features except Target/Outcome\n",
    "# the axis argument refers to columns (1); a 0 would represent rows\n",
    "scaler.fit(data.drop('outcome', axis=1))\n",
    "# Use scaler object to conduct a transform\n",
    "scaled_features = scaler.transform(data.drop('outcome',axis=1))#this does the standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10b5967d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>neutral</th>\n",
       "      <th>elo1_pre</th>\n",
       "      <th>elo2_pre</th>\n",
       "      <th>elo_prob1</th>\n",
       "      <th>elo_prob2</th>\n",
       "      <th>elo1_post</th>\n",
       "      <th>elo2_post</th>\n",
       "      <th>qbelo1_pre</th>\n",
       "      <th>qbelo2_pre</th>\n",
       "      <th>...</th>\n",
       "      <th>qb2_value_post</th>\n",
       "      <th>qbelo1_post</th>\n",
       "      <th>qbelo2_post</th>\n",
       "      <th>score1</th>\n",
       "      <th>score2</th>\n",
       "      <th>team1</th>\n",
       "      <th>team2</th>\n",
       "      <th>qb1</th>\n",
       "      <th>qb2</th>\n",
       "      <th>playoff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.209949</td>\n",
       "      <td>-0.082145</td>\n",
       "      <td>1.640269</td>\n",
       "      <td>1.418467</td>\n",
       "      <td>0.268167</td>\n",
       "      <td>-0.268167</td>\n",
       "      <td>1.200130</td>\n",
       "      <td>1.798469</td>\n",
       "      <td>1.683568</td>\n",
       "      <td>1.429136</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.175996</td>\n",
       "      <td>1.232109</td>\n",
       "      <td>1.813680</td>\n",
       "      <td>-1.172667</td>\n",
       "      <td>1.468332</td>\n",
       "      <td>1.006778</td>\n",
       "      <td>-0.974653</td>\n",
       "      <td>1.563539</td>\n",
       "      <td>0.789391</td>\n",
       "      <td>0.022504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.209949</td>\n",
       "      <td>-0.082145</td>\n",
       "      <td>-1.624783</td>\n",
       "      <td>-0.479055</td>\n",
       "      <td>-0.910380</td>\n",
       "      <td>0.910380</td>\n",
       "      <td>-1.836317</td>\n",
       "      <td>-0.214945</td>\n",
       "      <td>-1.669304</td>\n",
       "      <td>-0.489456</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.216065</td>\n",
       "      <td>-1.890359</td>\n",
       "      <td>-0.212817</td>\n",
       "      <td>-0.799584</td>\n",
       "      <td>1.759892</td>\n",
       "      <td>-1.479349</td>\n",
       "      <td>1.607859</td>\n",
       "      <td>-1.677005</td>\n",
       "      <td>1.105431</td>\n",
       "      <td>0.022504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.209949</td>\n",
       "      <td>-0.082145</td>\n",
       "      <td>-0.186920</td>\n",
       "      <td>-0.407535</td>\n",
       "      <td>0.245745</td>\n",
       "      <td>-0.245745</td>\n",
       "      <td>-0.485525</td>\n",
       "      <td>-0.090724</td>\n",
       "      <td>-0.187515</td>\n",
       "      <td>-0.411482</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.739222</td>\n",
       "      <td>-0.491443</td>\n",
       "      <td>-0.088839</td>\n",
       "      <td>-1.452480</td>\n",
       "      <td>-0.183841</td>\n",
       "      <td>1.106223</td>\n",
       "      <td>0.614585</td>\n",
       "      <td>0.021190</td>\n",
       "      <td>-1.122392</td>\n",
       "      <td>0.022504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.209949</td>\n",
       "      <td>-0.082145</td>\n",
       "      <td>-1.468643</td>\n",
       "      <td>-0.531399</td>\n",
       "      <td>-0.734399</td>\n",
       "      <td>0.734399</td>\n",
       "      <td>-1.742455</td>\n",
       "      <td>-0.206559</td>\n",
       "      <td>-1.501507</td>\n",
       "      <td>-0.540393</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.449708</td>\n",
       "      <td>-1.777333</td>\n",
       "      <td>-0.211088</td>\n",
       "      <td>-1.452480</td>\n",
       "      <td>2.440198</td>\n",
       "      <td>-0.484898</td>\n",
       "      <td>-0.676671</td>\n",
       "      <td>1.439936</td>\n",
       "      <td>-1.376261</td>\n",
       "      <td>0.022504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.209949</td>\n",
       "      <td>-0.082145</td>\n",
       "      <td>0.576637</td>\n",
       "      <td>1.235303</td>\n",
       "      <td>-0.473412</td>\n",
       "      <td>0.473412</td>\n",
       "      <td>0.413946</td>\n",
       "      <td>1.362041</td>\n",
       "      <td>0.605473</td>\n",
       "      <td>1.269953</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.698024</td>\n",
       "      <td>0.437334</td>\n",
       "      <td>1.396873</td>\n",
       "      <td>-0.239958</td>\n",
       "      <td>0.399279</td>\n",
       "      <td>0.111773</td>\n",
       "      <td>-1.173308</td>\n",
       "      <td>0.746685</td>\n",
       "      <td>0.152130</td>\n",
       "      <td>0.022504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     season   neutral  elo1_pre  elo2_pre  elo_prob1  elo_prob2  elo1_post  \\\n",
       "0 -2.209949 -0.082145  1.640269  1.418467   0.268167  -0.268167   1.200130   \n",
       "1 -2.209949 -0.082145 -1.624783 -0.479055  -0.910380   0.910380  -1.836317   \n",
       "2 -2.209949 -0.082145 -0.186920 -0.407535   0.245745  -0.245745  -0.485525   \n",
       "3 -2.209949 -0.082145 -1.468643 -0.531399  -0.734399   0.734399  -1.742455   \n",
       "4 -2.209949 -0.082145  0.576637  1.235303  -0.473412   0.473412   0.413946   \n",
       "\n",
       "   elo2_post  qbelo1_pre  qbelo2_pre  ...  qb2_value_post  qbelo1_post  \\\n",
       "0   1.798469    1.683568    1.429136  ...       -1.175996     1.232109   \n",
       "1  -0.214945   -1.669304   -0.489456  ...       -1.216065    -1.890359   \n",
       "2  -0.090724   -0.187515   -0.411482  ...       -1.739222    -0.491443   \n",
       "3  -0.206559   -1.501507   -0.540393  ...       -1.449708    -1.777333   \n",
       "4   1.362041    0.605473    1.269953  ...       -1.698024     0.437334   \n",
       "\n",
       "   qbelo2_post    score1    score2     team1     team2       qb1       qb2  \\\n",
       "0     1.813680 -1.172667  1.468332  1.006778 -0.974653  1.563539  0.789391   \n",
       "1    -0.212817 -0.799584  1.759892 -1.479349  1.607859 -1.677005  1.105431   \n",
       "2    -0.088839 -1.452480 -0.183841  1.106223  0.614585  0.021190 -1.122392   \n",
       "3    -0.211088 -1.452480  2.440198 -0.484898 -0.676671  1.439936 -1.376261   \n",
       "4     1.396873 -0.239958  0.399279  0.111773 -1.173308  0.746685  0.152130   \n",
       "\n",
       "    playoff  \n",
       "0  0.022504  \n",
       "1  0.022504  \n",
       "2  0.022504  \n",
       "3  0.022504  \n",
       "4  0.022504  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here we have the normalized dataset, minus the target/output column which is the last col\n",
    "data_feat = pd.DataFrame(scaled_features, columns= data.columns[:-1])\n",
    "#see what you did\n",
    "data_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "142f20eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset in features and target variable on the standardized data\n",
    "X = data_feat\n",
    "y = data['outcome'] # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c427b1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "# 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d26562e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def varyK(k, distMetric):\n",
    "    results = []\n",
    "    for i in range(1, k+1):\n",
    "        model = KNeighborsClassifier(n_neighbors=i, metric=distMetric)\n",
    "        model.fit(X_train,y_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        results.append(metrics.accuracy_score(y_test, y_test_pred))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7420918e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Flags' object has no attribute 'c_contiguous'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m EucAccuracy \u001b[38;5;241m=\u001b[39m varyK(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meuclidean\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m ManAccuracy \u001b[38;5;241m=\u001b[39m varyK(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmanhattan\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m ChedAccuracy \u001b[38;5;241m=\u001b[39m varyK(\u001b[38;5;241m100\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchebyshev\u001b[39m\u001b[38;5;124m'\u001b[39m )\n",
      "Cell \u001b[0;32mIn[11], line 6\u001b[0m, in \u001b[0;36mvaryK\u001b[0;34m(k, distMetric)\u001b[0m\n\u001b[1;32m      4\u001b[0m     model \u001b[38;5;241m=\u001b[39m KNeighborsClassifier(n_neighbors\u001b[38;5;241m=\u001b[39mi, metric\u001b[38;5;241m=\u001b[39mdistMetric)\n\u001b[1;32m      5\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit(X_train,y_train)\n\u001b[0;32m----> 6\u001b[0m     y_test_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m      7\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(metrics\u001b[38;5;241m.\u001b[39maccuracy_score(y_test, y_test_pred))\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m/opt/anaconda/lib/python3.11/site-packages/sklearn/neighbors/_classification.py:246\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    244\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_fit_method\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 246\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrute\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m ArgKminClassMode\u001b[38;5;241m.\u001b[39mis_usable_for(\n\u001b[1;32m    247\u001b[0m         X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric\n\u001b[1;32m    248\u001b[0m     ):\n\u001b[1;32m    249\u001b[0m         probabilities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_proba(X)\n\u001b[1;32m    250\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs_2d_:\n",
      "File \u001b[0;32m/opt/anaconda/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:471\u001b[0m, in \u001b[0;36mArgKminClassMode.is_usable_for\u001b[0;34m(cls, X, Y, metric)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_usable_for\u001b[39m(\u001b[38;5;28mcls\u001b[39m, X, Y, metric) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m    450\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return True if the dispatcher can be used for the given parameters.\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \n\u001b[1;32m    452\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;124;03m    True if the PairwiseDistancesReduction can be used, else False.\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 471\u001b[0m         ArgKmin\u001b[38;5;241m.\u001b[39mis_usable_for(X, Y, metric)\n\u001b[1;32m    472\u001b[0m         \u001b[38;5;66;03m# TODO: Support CSR matrices.\u001b[39;00m\n\u001b[1;32m    473\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m issparse(X)\n\u001b[1;32m    474\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m issparse(Y)\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;66;03m# TODO: implement Euclidean specialization with GEMM.\u001b[39;00m\n\u001b[1;32m    476\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m metric \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meuclidean\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqeuclidean\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    477\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:115\u001b[0m, in \u001b[0;36mBaseDistancesReductionDispatcher.is_usable_for\u001b[0;34m(cls, X, Y, metric)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_valid_sparse_matrix\u001b[39m(X):\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    103\u001b[0m         isspmatrix_csr(X)\n\u001b[1;32m    104\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    110\u001b[0m         X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mint32\n\u001b[1;32m    111\u001b[0m     )\n\u001b[1;32m    113\u001b[0m is_usable \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    114\u001b[0m     get_config()\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menable_cython_pairwise_dist\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (is_numpy_c_ordered(X) \u001b[38;5;129;01mor\u001b[39;00m is_valid_sparse_matrix(X))\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (is_numpy_c_ordered(Y) \u001b[38;5;129;01mor\u001b[39;00m is_valid_sparse_matrix(Y))\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m Y\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01min\u001b[39;00m (np\u001b[38;5;241m.\u001b[39mfloat32, np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mvalid_metrics()\n\u001b[1;32m    120\u001b[0m )\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_usable\n",
      "File \u001b[0;32m/opt/anaconda/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:99\u001b[0m, in \u001b[0;36mBaseDistancesReductionDispatcher.is_usable_for.<locals>.is_numpy_c_ordered\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_numpy_c_ordered\u001b[39m(X):\n\u001b[0;32m---> 99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflags\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m X\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mc_contiguous\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Flags' object has no attribute 'c_contiguous'"
     ]
    }
   ],
   "source": [
    "EucAccuracy = varyK(100, 'euclidean')\n",
    "ManAccuracy = varyK(100, 'manhattan')\n",
    "ChedAccuracy = varyK(100,'chebyshev' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add92ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "kneighbors = [*range(1, 101)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1423be",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(kneighbors, EucAccuracy, color='green', label='Euclidean')\n",
    "ax.plot(kneighbors, ManAccuracy, color='red', label='Manhattan')\n",
    "ax.plot(kneighbors, ChedAccuracy, color='blue', label='Chebyshev')\n",
    "ax.legend(loc= 'upper right')\n",
    "plt.xlabel('Value of k for KNN')\n",
    "plt.ylabel('Testing Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509902eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "EucAccuracy = varyK(40, 'euclidean')\n",
    "ManAccuracy = varyK(40, 'manhattan')\n",
    "ChedAccuracy = varyK(40,'chebyshev' )\n",
    "kneighbors = [*range(1, 41)]\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(kneighbors, EucAccuracy, color='green', label='Euclidean')\n",
    "ax.plot(kneighbors, ManAccuracy, color='red', label='Manhattan')\n",
    "ax.plot(kneighbors, ChedAccuracy, color='blue', label='Chebyshev')\n",
    "plt.xlabel('Value of k for KNN')\n",
    "plt.ylabel('Testing Accuracy')\n",
    "ax.legend(loc= 'lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e051c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "#number of n =\n",
    "n = X_train.shape[0]#how many samples in training\n",
    "print(n)\n",
    "print(math.sqrt(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5c9b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def varyWeightedK(k, distMetric):\n",
    "    results = []\n",
    "    for i in range(1, k+1):\n",
    "        model = KNeighborsClassifier(n_neighbors=i,weights='distance', metric=distMetric)\n",
    "        model.fit(X_train,y_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        results.append(metrics.accuracy_score(y_test, y_test_pred))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dcf80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=55\n",
    "EucAccuracy = varyK(k, 'euclidean')\n",
    "ManAccuracy = varyK(k, 'manhattan')\n",
    "ChedAccuracy = varyK(k,'chebyshev' )\n",
    "EucWeightedAccuracy = varyWeightedK(k, 'euclidean')\n",
    "ManWeightedAccuracy = varyWeightedK(k, 'manhattan')\n",
    "ChedWeightedAccuracy = varyWeightedK(k,'chebyshev' )\n",
    "kneighbors = [*range(1, k+1)]\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(kneighbors, EucAccuracy, color='green', label='Euclidean')\n",
    "ax.plot(kneighbors, ManAccuracy, color='red', label='Manhattan')\n",
    "ax.plot(kneighbors, ChedAccuracy, color='blue', label='Chebyshev')\n",
    "ax.plot(kneighbors, EucWeightedAccuracy, linestyle='--', color='green', label='Weighted Euclidean')\n",
    "ax.plot(kneighbors, ManWeightedAccuracy, linestyle='--', color='red', label='Weighted Manhattan')\n",
    "ax.plot(kneighbors, ChedWeightedAccuracy, linestyle='--', color='blue', label='Weighted Chebyshev')\n",
    "plt.xlabel('Value of k for KNN')\n",
    "plt.ylabel('Testing Accuracy')\n",
    "ax.legend(loc= 'lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85250acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure you have your labels correct\n",
    "#some files have this in the file - others it is in the description\n",
    "#if it is in the file you can copy them here then delete that line in the file\n",
    "col_names = ['Driver Substance Abuse','Speed Limit','Driverless Vehicle','Parked Vehicle','Driver At Fault']\n",
    "# load dataset\n",
    "data = pd.read_csv(\"Crash_reporting.csv\", header=None, names=col_names)\n",
    "#take a peek to see if this looks right\n",
    "data.head() #optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed4e057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import module to standardize the scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Create instance (i.e. object) of the standard scaler\n",
    "scaler = StandardScaler()\n",
    "# Fit the object to all the data except the Target/Outcome\n",
    "# use the .drop() method to gather all features except Target/Outcome\n",
    "# the axis argument refers to columns (1); a 0 would represent rows\n",
    "scaler.fit(data.drop('Driver At Fault', axis=1))\n",
    "# Use scaler object to conduct a transform\n",
    "scaled_features = scaler.transform(data.drop('Driver At Fault', axis=1))#this does the standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b0dfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we have the normalized dataset, minus the target/output column which is the last col\n",
    "data_feat = pd.DataFrame(scaled_features, columns= data.columns[:-1])\n",
    "#see what you did\n",
    "data_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6878b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset in features and target variable on the standardized data\n",
    "X = data_feat\n",
    "y = data['Driver At Fault'] # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f6a66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "# 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce386178",
   "metadata": {},
   "outputs": [],
   "source": [
    "def varyK(k, distMetric):\n",
    "    results = []\n",
    "    for i in range(1, k+1):\n",
    "        model = KNeighborsClassifier(n_neighbors=i, metric=distMetric)\n",
    "        model.fit(X_train,y_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        results.append(metrics.accuracy_score(y_test, y_test_pred))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366e14de",
   "metadata": {},
   "outputs": [],
   "source": [
    "EucAccuracy = varyK(100, 'euclidean')\n",
    "ManAccuracy = varyK(100, 'manhattan')\n",
    "ChedAccuracy = varyK(100,'chebyshev' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7ae333",
   "metadata": {},
   "outputs": [],
   "source": [
    "kneighbors = [*range(1, 101)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5937badd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(kneighbors, EucAccuracy, color='green', label='Euclidean')\n",
    "ax.plot(kneighbors, ManAccuracy, color='red', label='Manhattan')\n",
    "ax.plot(kneighbors, ChedAccuracy, color='blue', label='Chebyshev')\n",
    "ax.legend(loc= 'upper right')\n",
    "plt.xlabel('Value of k for KNN')\n",
    "plt.ylabel('Testing Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d24b38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "EucAccuracy = varyK(40, 'euclidean')\n",
    "ManAccuracy = varyK(40, 'manhattan')\n",
    "ChedAccuracy = varyK(40,'chebyshev' )\n",
    "kneighbors = [*range(1, 41)]\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(kneighbors, EucAccuracy, color='green', label='Euclidean')\n",
    "ax.plot(kneighbors, ManAccuracy, color='red', label='Manhattan')\n",
    "ax.plot(kneighbors, ChedAccuracy, color='blue', label='Chebyshev')\n",
    "plt.xlabel('Value of k for KNN')\n",
    "plt.ylabel('Testing Accuracy')\n",
    "ax.legend(loc= 'lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9a2a6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f335edbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
